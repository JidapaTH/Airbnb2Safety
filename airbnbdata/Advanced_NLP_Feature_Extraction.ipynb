{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\data-x\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import csv\n",
    "import pickle\n",
    "import gensim\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # to suppress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load review data\n",
    "filePath = \"../Data/\"\n",
    "review_by_zipcode = pickle.load( open( filePath+\"balanced_review_by_zipcode.p\", \"rb\" ) ) # Dataset accessible from https://drive.google.com/open?id=1GbFVIStnd2xVnFTFE43KGkveO7w066aW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get word count for each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"nltk_pack\", \"../toolkit/nltk_pack.py\")\n",
    "pack = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function operates on one row of review_by_zipcode.\n",
    "# Clean the text and extracts unique words and corresponding word frequency from the concatenated review in this row\n",
    "# @param rev is one row in the review_by_zipcode\n",
    "# @returns a df with first column is the unique words and second column being the word frequency\n",
    "def getWordCt(rev):\n",
    "    word_count = pack.getwordlist([rev[\"review\"]])\n",
    "    return word_count\n",
    "\n",
    "# Compare all words against each word in the dictionary of user-defined words related to safety\n",
    "# and output a similarity score for each dict word per row in the review_by_zipcode\n",
    "# @param myDict a list of words related to safety\n",
    "# @rev is one row in the review_by_zipcode data set\n",
    "# @returns a vector with its length = the size of myDict\n",
    "def getSimilarityScore(rev, myDict):\n",
    "    wordCt = getWordCt(rev)\n",
    "    \n",
    "    # initizalize similarity matrix: nRow = number of unique words from wordCt, ncol = number of words in dictionary\n",
    "    simMat = np.zeros((wordCt.shape[0],len(myDict)))\n",
    "    \n",
    "    # iterate through all unique words (rows)\n",
    "    for i in range(wordCt.shape[0]):\n",
    "        # iterate through all benchmark words (cols)\n",
    "        for j in range(len(myDict)):\n",
    "            # if a word does not exist in the Google model (error thrown), assign 0 to the similarity score.\n",
    "            try:\n",
    "                simMat[i,j] = wv.similarity(wordCt.loc[i,\"index\"], myDict[j]) * wordCt.iloc[i,1]  # calculate similarity score between each unique word and each benchmark word. weight by the frequency of the word\n",
    "            except:\n",
    "                simMat[i,j] = 0\n",
    "    # calculate similarity score for each zipcode as whole by summing up the score for each word and divided by number of reviews for this zipcode\n",
    "    simScores = np.sum(simMat,axis = 0)/rev.ct  # should be a 1 x k vector, k = size of dictionary\n",
    "    return simScores           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate similarity features for all zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5% done\n",
      "10% done\n",
      "15% done\n",
      "20% done\n",
      "25% done\n",
      "30% done\n",
      "35% done\n",
      "40% done\n",
      "45% done\n",
      "50% done\n",
      "55% done\n",
      "60% done\n",
      "65% done\n",
      "70% done\n",
      "76% done\n",
      "81% done\n",
      "86% done\n",
      "91% done\n",
      "96% done\n"
     ]
    }
   ],
   "source": [
    "safetyKeyWd = [\"good\", \"safe\",\"night\", \"walk\", \"unsafe\", \"bad\", \"dangerous\"]\n",
    "# load pre-trained word2vec model from Google\n",
    "wv = pickle.load( open( filePath+\"wv.p\", \"rb\" ) ) # model accessible from https://drive.google.com/open?id=1bKML3D_7AQfoZg_z7ju--WoMMS-huPBY\n",
    "    \n",
    "# initialize numeric representation of similarity score\n",
    "textFeatures = np.zeros((review_by_zipcode.shape[0],len(safetyKeyWd)))\n",
    "\n",
    "nRow = review_by_zipcode.shape[0]\n",
    "\n",
    "# calculate and aggregate similarity score for reviews corresponding to all zipcodes\n",
    "for i, row in review_by_zipcode.reset_index().iterrows(): \n",
    "    textFeatures[i,:] = getSimilarityScore(row, myDict=safetyKeyWd)\n",
    "    # output progress of this for-loop\n",
    "    if( (i+1)%15 == 0 ):\n",
    "        print(\"%d%% done\" %((i+1)/nRow * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good</th>\n",
       "      <th>safe</th>\n",
       "      <th>night</th>\n",
       "      <th>walk</th>\n",
       "      <th>unsafe</th>\n",
       "      <th>bad</th>\n",
       "      <th>dangerous</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10019</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10023</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37738</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60601</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90001</th>\n",
       "      <td>3.635028</td>\n",
       "      <td>2.55469</td>\n",
       "      <td>1.890825</td>\n",
       "      <td>2.229291</td>\n",
       "      <td>1.415911</td>\n",
       "      <td>2.522453</td>\n",
       "      <td>1.730858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             good     safe     night      walk    unsafe       bad  dangerous\n",
       "zipcode                                                                      \n",
       "10019         NaN      NaN       NaN       NaN       NaN       NaN        NaN\n",
       "10023         NaN      NaN       NaN       NaN       NaN       NaN        NaN\n",
       "37738         NaN      NaN       NaN       NaN       NaN       NaN        NaN\n",
       "60601         NaN      NaN       NaN       NaN       NaN       NaN        NaN\n",
       "90001    3.635028  2.55469  1.890825  2.229291  1.415911  2.522453   1.730858"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFeatureDF = pd.DataFrame(textFeatures, columns= safetyKeyWd, index=review_by_zipcode.index)\n",
    "textFeatureDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write result to local storage\n",
    "pickle.dump(textFeatures, open( filePath+\"textFeatures.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "textFeatureDF.to_csv(filePath+\"textFeatures.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word do not exist\n"
     ]
    }
   ],
   "source": [
    "# for testing\n",
    "try:\n",
    "    print(wv.similarity(\"safe\", \"tanya\"))\n",
    "except:\n",
    "    print(\"Word do not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good         17\n",
       "safe         17\n",
       "night        17\n",
       "walk         17\n",
       "unsafe       17\n",
       "bad          17\n",
       "dangerous    17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for testing\n",
    "review_by_zipcode.loc[37738,]\n",
    "textFeatureDF.isna().sum(axis = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
